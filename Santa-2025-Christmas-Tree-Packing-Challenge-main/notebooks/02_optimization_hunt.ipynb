{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f41f752",
   "metadata": {},
   "source": [
    "# Santa 2025 - Optimization Hunt (Notebook)\n",
    "\n",
    "Este notebook faz uma busca (hunt) para tentar melhorar o score do seu `BASE_SUBMISSION` (calculado abaixo) usando uma estratégia prática:\n",
    "\n",
    "1. **Hunt em N=200** com `santa_packing._tools.hunt_compact_contact` (múltiplos seeds + jobs) e polish opcional (`bin/post_opt`).\n",
    "2. **Mother prefix**: gera soluções para N=1..199 pegando o prefixo da solução de N=200.\n",
    "3. **Pós-processamento**: `santa_packing.cli.improve_submission` com varredura de `--smooth-window` + `--improve-n200`.\n",
    "4. **Validação Kaggle** (`overlap_mode=\"kaggle\"`) e **autofix** apenas se necessário.\n",
    "\n",
    "Tudo roda dentro do notebook (sem `subprocess` para CLIs Python).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f773d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/marcux777/Santa-2025-Christmas-Tree-Packing-Challenge\n",
      "JOBS=14\n",
      "OVERLAP_MODE=kaggle\n",
      "RUN_DIR=runs/notebook_optimization_hunt_20260111_103707\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# --- SETUP PATHS (run from repo root or notebooks/) ---\n",
    "current_path = Path.cwd().resolve()\n",
    "if (current_path / \"santa_packing\").exists():\n",
    "    project_root = current_path\n",
    "elif (current_path.parent / \"santa_packing\").exists():\n",
    "    project_root = current_path.parent\n",
    "else:\n",
    "    raise RuntimeError(\"Could not find repo root (missing santa_packing/)\")\n",
    "\n",
    "os.chdir(project_root)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "os.environ[\"PYTHONPATH\"] = f\"{project_root}:{os.environ.get('PYTHONPATH','')}\"\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# --- Meta / objetivo ---\n",
    "# `CURRENT_BEST` é calculado automaticamente a partir do BASE_SUBMISSION (com OVERLAP_MODE).\n",
    "CURRENT_BEST = None\n",
    "\n",
    "# Pare cedo quando atingir este score (use None para desativar)\n",
    "TARGET_SCORE = 69.999999  # objetivo: ficar < 70\n",
    "\n",
    "# --- Main knobs ---\n",
    "NMAX = 200\n",
    "JOBS = max(1, (os.cpu_count() or 16) - 2)\n",
    "OVERLAP_MODE = \"strict\"  # strict | conservative | kaggle\n",
    "\n",
    "# Coloque aqui o seu CSV (pode ser absoluto), ex:\n",
    "# BASE_SUBMISSION = Path(\"/caminho/para/submission_70_78.csv\")\n",
    "BASE_SUBMISSION = Path(\"submission.csv\")\n",
    "\n",
    "# Se o BASE_SUBMISSION tiver overlap em OVERLAP_MODE, escolha o que fazer:\n",
    "# - \"solve\": gera um baseline kaggle-safe via `santa_packing.workflow.solve` (mais lento)\n",
    "# - \"mother_prefix\": tenta reparar via mother-prefix (rápido, mas pode piorar score)\n",
    "# - \"autofix\": roda autofix completo (muito lento)\n",
    "# - \"abort\": para com erro\n",
    "BASE_INVALID_ACTION = \"solve\"\n",
    "BASE_INVALID_SOLVE_CONFIG = Path(\"configs/submit_strong.json\")\n",
    "\n",
    "RUN_TAG = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = Path(\"runs\") / f\"notebook_optimization_hunt_{RUN_TAG}\"\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"JOBS={JOBS}\")\n",
    "print(f\"OVERLAP_MODE={OVERLAP_MODE}\")\n",
    "print(f\"RUN_DIR={RUN_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf0ac7e",
   "metadata": {},
   "source": [
    "## 0. Utilitários\n",
    "Funções auxiliares para rodar o pipeline (sem subprocess), score Kaggle, gerar prefixos e registrar o melhor candidato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061e5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import contextlib\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def score_csv(csv_path: Path, *, overlap_mode: str, check_overlap: bool = True) -> float:\n",
    "    from santa_packing.scoring import score_submission\n",
    "\n",
    "    res = score_submission(\n",
    "        Path(csv_path),\n",
    "        nmax=int(NMAX),\n",
    "        check_overlap=bool(check_overlap),\n",
    "        overlap_mode=str(overlap_mode),\n",
    "        require_complete=True,\n",
    "    )\n",
    "    return float(res.score)\n",
    "\n",
    "\n",
    "def try_score(csv_path: Path) -> tuple[bool, float | None, str | None]:\n",
    "    try:\n",
    "        s = score_csv(csv_path, overlap_mode=str(OVERLAP_MODE), check_overlap=True)\n",
    "        return True, s, None\n",
    "    except Exception as e:\n",
    "        return False, None, str(e)\n",
    "\n",
    "\n",
    "def _call_main(main_func, argv: list[str]) -> None:\n",
    "    try:\n",
    "        rc = int(main_func(argv))\n",
    "    except SystemExit as e:\n",
    "        rc = int(e.code or 1)\n",
    "    if rc != 0:\n",
    "        name = getattr(main_func, \"__module__\", \"main\")\n",
    "        raise RuntimeError(f\"{name} failed (rc={rc})\")\n",
    "\n",
    "\n",
    "def autofix(inp: Path, out: Path, *, seed: int = 123) -> Path:\n",
    "    from santa_packing.cli.autofix_submission import main as autofix_main\n",
    "\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    argv = [\n",
    "        str(inp),\n",
    "        \"--out\",\n",
    "        str(out),\n",
    "        \"--nmax\",\n",
    "        str(int(NMAX)),\n",
    "        \"--overlap-mode\",\n",
    "        str(OVERLAP_MODE),\n",
    "        \"--seed\",\n",
    "        str(int(seed)),\n",
    "    ]\n",
    "    _call_main(autofix_main, argv)\n",
    "    return out\n",
    "\n",
    "\n",
    "def detouch_fast(inp: Path, out: Path, *, max_scale: float = 1.02) -> Path:\n",
    "    \"\"\"Fast Kaggle-safe detouch (scale-only). If it can't fix, it raises.\"\"\"\n",
    "    from santa_packing.scoring import first_overlap_pair, load_submission\n",
    "    from santa_packing.submission_format import fit_xy_in_bounds, quantize_for_submission\n",
    "    from santa_packing.cli.improve_submission import _write_submission\n",
    "    from santa_packing.tree_data import TREE_POINTS\n",
    "\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    points = np.array(TREE_POINTS, dtype=float)\n",
    "    puzzles = load_submission(inp, nmax=int(NMAX))\n",
    "    fixed: dict[int, np.ndarray] = {}\n",
    "\n",
    "    def _try_scale(points: np.ndarray, poses: np.ndarray, scale: float) -> np.ndarray | None:\n",
    "        cand = np.array(poses, dtype=float, copy=True)\n",
    "        center = np.mean(cand[:, 0:2], axis=0)\n",
    "        cand[:, 0:2] = center[None, :] + (cand[:, 0:2] - center[None, :]) * float(scale)\n",
    "        cand = fit_xy_in_bounds(cand)\n",
    "        cand = quantize_for_submission(cand)\n",
    "        if first_overlap_pair(points, cand, mode=str(OVERLAP_MODE)) is None:\n",
    "            return cand\n",
    "        return None\n",
    "\n",
    "    for n in range(1, int(NMAX) + 1):\n",
    "        poses = puzzles.get(n)\n",
    "        if poses is None or poses.shape != (n, 3):\n",
    "            raise RuntimeError(f\"Missing puzzle {n} or wrong shape {None if poses is None else poses.shape}\")\n",
    "\n",
    "        poses = fit_xy_in_bounds(poses)\n",
    "        poses = quantize_for_submission(poses)\n",
    "        if first_overlap_pair(points, poses, mode=str(OVERLAP_MODE)) is None:\n",
    "            fixed[n] = poses\n",
    "            continue\n",
    "\n",
    "        hi = float(max_scale)\n",
    "        cand_hi = _try_scale(points, poses, hi)\n",
    "        if cand_hi is None:\n",
    "            raise RuntimeError(f\"fast detouch failed for puzzle {n} (need > max_scale={max_scale})\")\n",
    "\n",
    "        lo = 1.0\n",
    "        best = hi\n",
    "        for _ in range(24):\n",
    "            mid = 0.5 * (lo + best)\n",
    "            if _try_scale(points, poses, mid) is not None:\n",
    "                best = mid\n",
    "            else:\n",
    "                lo = mid\n",
    "\n",
    "        fixed[n] = _try_scale(points, poses, best) or cand_hi\n",
    "\n",
    "    _write_submission(out, fixed, nmax=int(NMAX))\n",
    "    return out\n",
    "\n",
    "\n",
    "def improve_submission(inp: Path, out: Path, *, smooth_window: int, improve_n200: bool = True) -> Path:\n",
    "    from santa_packing.cli.improve_submission import main as improve_main\n",
    "\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    argv = [\n",
    "        str(inp),\n",
    "        \"--out\",\n",
    "        str(out),\n",
    "        \"--nmax\",\n",
    "        str(int(NMAX)),\n",
    "        \"--smooth-window\",\n",
    "        str(int(smooth_window)),\n",
    "        \"--overlap-mode\",\n",
    "        str(OVERLAP_MODE),\n",
    "    ]\n",
    "    if bool(improve_n200) and int(NMAX) >= 200:\n",
    "        argv.append(\"--improve-n200\")\n",
    "        # Extra knobs (safe defaults if not defined in the config cell)\n",
    "        insert_centers = int(globals().get(\"N200_INSERT_CENTERS\", 4000))\n",
    "        insert_angles = int(globals().get(\"N200_INSERT_ANGLES\", 20))\n",
    "        insert_pad = float(globals().get(\"N200_INSERT_PAD_SCALE\", 0.15))\n",
    "        sa_batch = int(globals().get(\"N200_SA_BATCH\", 32))\n",
    "        sa_steps = int(globals().get(\"N200_SA_STEPS\", 5000))\n",
    "        argv += [\n",
    "            \"--n200-insert-centers\",\n",
    "            str(insert_centers),\n",
    "            \"--n200-insert-angles\",\n",
    "            str(insert_angles),\n",
    "            \"--n200-insert-pad-scale\",\n",
    "            str(insert_pad),\n",
    "            \"--n200-sa-batch\",\n",
    "            str(sa_batch),\n",
    "            \"--n200-sa-steps\",\n",
    "            str(sa_steps),\n",
    "        ]\n",
    "\n",
    "    try:\n",
    "        _call_main(improve_main, argv)\n",
    "    except Exception as e:\n",
    "        if \"--improve-n200\" not in argv:\n",
    "            raise\n",
    "        print(f\"[warn] improve_submission failed with --improve-n200; retrying without it: {e}\")\n",
    "        argv2 = [tok for tok in argv if tok != \"--improve-n200\"]\n",
    "        _call_main(improve_main, argv2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def generate_mother_prefix(mother_csv: Path, out_csv: Path, *, reorder: str = \"radial\") -> Path:\n",
    "    # Build submission N=1..NMAX by prefix-slicing puzzle NMAX (mother layout).\n",
    "    # Important: repair/finalize the mother (NMAX) packing first so ALL prefixes are overlap-free.\n",
    "    from santa_packing.cli.generate_submission import _finalize_puzzle\n",
    "    from santa_packing.cli.generate_submission import _radial_reorder\n",
    "    from santa_packing.cli.improve_submission import _write_submission\n",
    "    from santa_packing.geom_np import polygon_bbox, transform_polygon\n",
    "    from santa_packing.tree_data import TREE_POINTS\n",
    "\n",
    "    def _parse_val(v: str) -> float:\n",
    "        v = v.strip()\n",
    "        if v[:1] in (\"s\", \"S\"):\n",
    "            v = v[1:]\n",
    "        return float(v)\n",
    "\n",
    "    mother_rows: list[tuple[int, float, float, float]] = []\n",
    "    with mother_csv.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            n_str, i_str = row[\"id\"].split(\"_\", 1)\n",
    "            if int(n_str) != int(NMAX):\n",
    "                continue\n",
    "            mother_rows.append(\n",
    "                (\n",
    "                    int(i_str),\n",
    "                    _parse_val(row[\"x\"]),\n",
    "                    _parse_val(row[\"y\"]),\n",
    "                    _parse_val(row[\"deg\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    mother_rows.sort(key=lambda t: t[0])\n",
    "    if len(mother_rows) != int(NMAX):\n",
    "        raise RuntimeError(f\"Expected {NMAX} rows for puzzle {NMAX}, got {len(mother_rows)}\")\n",
    "\n",
    "    poses = np.array([[x, y, deg] for (_i, x, y, deg) in mother_rows], dtype=float)\n",
    "    points = np.array(TREE_POINTS, dtype=float)\n",
    "    poses = _finalize_puzzle(points, poses, seed=123, puzzle_n=int(NMAX), overlap_mode=str(OVERLAP_MODE))\n",
    "\n",
    "    reorder_key = str(reorder).lower().strip()\n",
    "    if reorder_key == \"radial\":\n",
    "        poses = _radial_reorder(points, poses)\n",
    "    elif reorder_key == \"greedybbox\":\n",
    "        # Greedy ordering that minimizes prefix AABB growth (fast, no JAX needed).\n",
    "        bboxes = np.array([polygon_bbox(transform_polygon(points, pose)) for pose in poses], dtype=float)\n",
    "        single = np.maximum(bboxes[:, 2] - bboxes[:, 0], bboxes[:, 3] - bboxes[:, 1])\n",
    "        start = int(np.argmin(single))\n",
    "\n",
    "        order: list[int] = [start]\n",
    "        remaining = set(range(int(NMAX)))\n",
    "        remaining.remove(start)\n",
    "        min_x, min_y, max_x, max_y = (float(x) for x in bboxes[start])\n",
    "\n",
    "        while remaining:\n",
    "            best_idx = None\n",
    "            best_side = None\n",
    "            best_bbox = None\n",
    "            for idx in remaining:\n",
    "                b = bboxes[int(idx)]\n",
    "                nx = min(min_x, float(b[0]))\n",
    "                ny = min(min_y, float(b[1]))\n",
    "                mx = max(max_x, float(b[2]))\n",
    "                my = max(max_y, float(b[3]))\n",
    "                side = max(mx - nx, my - ny)\n",
    "                if best_side is None or side < best_side - 1e-12:\n",
    "                    best_side = float(side)\n",
    "                    best_idx = int(idx)\n",
    "                    best_bbox = (nx, ny, mx, my)\n",
    "            assert best_idx is not None and best_bbox is not None\n",
    "            order.append(best_idx)\n",
    "            remaining.remove(best_idx)\n",
    "            min_x, min_y, max_x, max_y = best_bbox\n",
    "\n",
    "        poses = poses[np.array(order, dtype=int)]\n",
    "    elif reorder_key in {\"none\", \"\"}:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown reorder={reorder!r} (use 'radial', 'greedybbox', or 'none')\")\n",
    "\n",
    "    puzzles = {n: np.array(poses[:n], dtype=float, copy=True) for n in range(1, int(NMAX) + 1)}\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    _write_submission(out_csv, puzzles, nmax=int(NMAX))\n",
    "    return out_csv\n",
    "\n",
    "\n",
    "def run_hunt_compact_contact(\n",
    "    *,\n",
    "    base: Path,\n",
    "    out_dir: Path,\n",
    "    seeds: str,\n",
    "    target_range: str,\n",
    "    passes: int,\n",
    "    attempts_per_pass: int,\n",
    "    post_opt: bool,\n",
    "    post_iters: int,\n",
    "    post_restarts: int,\n",
    ") -> Path:\n",
    "    from santa_packing._tools.hunt_compact_contact import main as hunt_main\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    argv = [\n",
    "        \"--base\",\n",
    "        str(base),\n",
    "        \"--out-dir\",\n",
    "        str(out_dir),\n",
    "        \"--seeds\",\n",
    "        str(seeds),\n",
    "        \"--jobs\",\n",
    "        str(int(JOBS)),\n",
    "        \"--nmax\",\n",
    "        str(int(NMAX)),\n",
    "        \"--target-range\",\n",
    "        str(target_range),\n",
    "        \"--passes\",\n",
    "        str(int(passes)),\n",
    "        \"--attempts-per-pass\",\n",
    "        str(int(attempts_per_pass)),\n",
    "        \"--ensemble-out\",\n",
    "        str(out_dir / \"ensemble.csv\"),\n",
    "        \"--choices-out\",\n",
    "        str(out_dir / \"ensemble_choices.csv\"),\n",
    "    ]\n",
    "\n",
    "    if bool(post_opt):\n",
    "        argv += [\n",
    "            \"--post-opt\",\n",
    "            \"--post-iters\",\n",
    "            str(int(post_iters)),\n",
    "            \"--post-restarts\",\n",
    "            str(int(post_restarts)),\n",
    "            \"--post-overlap-mode\",\n",
    "            str(OVERLAP_MODE),\n",
    "        ]\n",
    "\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buf):\n",
    "        try:\n",
    "            rc = int(hunt_main(argv))\n",
    "        except SystemExit as e:\n",
    "            rc = int(e.code or 1)\n",
    "    if rc != 0:\n",
    "        raise RuntimeError(f\"hunt_compact_contact failed (rc={rc})\")\n",
    "\n",
    "    last = [ln.strip() for ln in buf.getvalue().splitlines() if ln.strip()][-1]\n",
    "    return Path(last)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Candidate:\n",
    "    label: str\n",
    "    csv_path: Path\n",
    "    score: float\n",
    "\n",
    "\n",
    "def save_leaderboard(rows: list[Candidate], path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(\n",
    "            [\n",
    "                {\n",
    "                    \"label\": r.label,\n",
    "                    \"csv_path\": str(r.csv_path),\n",
    "                    \"score\": r.score,\n",
    "                }\n",
    "                for r in sorted(rows, key=lambda x: x.score)\n",
    "            ],\n",
    "            f,\n",
    "            indent=2,\n",
    "        )\n",
    "\n",
    "\n",
    "# --- Validate BASE_SUBMISSION once (keep a kaggle-safe base for the hunt loop) ---\n",
    "BASE_SUBMISSION_RAW = Path(BASE_SUBMISSION)\n",
    "BASE_WAS_INVALID = False\n",
    "if not BASE_SUBMISSION_RAW.is_file():\n",
    "    raise FileNotFoundError(f\"BASE_SUBMISSION not found: {BASE_SUBMISSION_RAW}\")\n",
    "\n",
    "base_ok, base_score, base_err = try_score(BASE_SUBMISSION_RAW)\n",
    "if base_ok:\n",
    "    BASE_SUBMISSION = BASE_SUBMISSION_RAW\n",
    "else:\n",
    "    BASE_WAS_INVALID = True\n",
    "    print(f\"[warn] BASE_SUBMISSION tem overlap ({base_err}).\")\n",
    "    print(f\"[info] Vou criar um baseline válido (kaggle-safe) via BASE_INVALID_ACTION={BASE_INVALID_ACTION!r}.\")\n",
    "\n",
    "    action = str(BASE_INVALID_ACTION).lower().strip()\n",
    "    if action == \"mother_prefix\":\n",
    "        mother_fixed = RUN_DIR / \"base_mother_prefix.csv\"\n",
    "        mother_fixed = generate_mother_prefix(BASE_SUBMISSION_RAW, mother_fixed)\n",
    "        base_ok, base_score, base_err = try_score(mother_fixed)\n",
    "        if not base_ok:\n",
    "            raise RuntimeError(f\"mother-prefix ainda inválido: {base_err}\")\n",
    "        BASE_SUBMISSION = mother_fixed\n",
    "    elif action == \"autofix\":\n",
    "        fixed = RUN_DIR / \"base_autofixed.csv\"\n",
    "        fixed = autofix(BASE_SUBMISSION_RAW, fixed, seed=123)\n",
    "        base_ok, base_score, base_err = try_score(fixed)\n",
    "        if not base_ok:\n",
    "            raise RuntimeError(f\"autofix ainda inválido: {base_err}\")\n",
    "        BASE_SUBMISSION = fixed\n",
    "    elif action == \"solve\":\n",
    "        from santa_packing.workflow import solve\n",
    "\n",
    "        cfg = Path(BASE_INVALID_SOLVE_CONFIG)\n",
    "        if not cfg.is_file():\n",
    "            raise FileNotFoundError(f\"Config não encontrado: {cfg}\")\n",
    "\n",
    "        res = solve(\n",
    "            nmax=int(NMAX),\n",
    "            overlap_mode=str(OVERLAP_MODE),\n",
    "            config=cfg,\n",
    "            improve=True,\n",
    "            smooth_window=60,\n",
    "            improve_n200=True,\n",
    "            autofix=True,\n",
    "            export=False,\n",
    "        )\n",
    "        base_ok, base_score, base_err = try_score(res.final_submission)\n",
    "        if not base_ok:\n",
    "            raise RuntimeError(f\"solve() produziu um CSV inválido: {base_err}\")\n",
    "        BASE_SUBMISSION = res.final_submission\n",
    "    elif action == \"abort\":\n",
    "        raise RuntimeError(f\"BASE_SUBMISSION inválido: {base_err}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown BASE_INVALID_ACTION={BASE_INVALID_ACTION!r}\")\n",
    "\n",
    "CURRENT_BEST = float(base_score)\n",
    "print(f\"BASE_SUBMISSION_RAW: {BASE_SUBMISSION_RAW}\")\n",
    "print(f\"BASE_SUBMISSION (valid): {BASE_SUBMISSION}\")\n",
    "print(f\"BASE_SCORE: {CURRENT_BEST:.12f} (overlap_mode={OVERLAP_MODE})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8378e6",
   "metadata": {},
   "source": [
    "## 1. Configurar o Hunt\n",
    "Sugestão: rode por blocos de seeds (ex: 4000..4127) e acumule resultados no `RUN_DIR`.\n",
    "\n",
    "Dica: comece em `MODE=\"quick\"` para validar o pipeline; depois aumente seeds/passes/iters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b3308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MODE': 'full', 'SEED_BLOCKS': ['4000..4015', '4016..4031', '4032..4047', '4048..4063', '4064..4079', '4080..4095', '4096..4111', '4112..4127'], 'PASSES': 5000, 'ATTEMPTS_PER_PASS': 500, 'POST_OPT': True, 'POST_ITERS': 200000, 'POST_RESTARTS': 64, 'SMOOTH_WINDOWS': [0, 60, 80, 100, 120, 140, 160, 180, 199], 'IMPROVE_N200_OPTIONS': [False, True]}\n"
     ]
    }
   ],
   "source": [
    "MODE = \"target70\"  # quick | full | target70\n",
    "\n",
    "# Estratégia do hunt:\n",
    "# - best: usa o melhor atual (kaggle-safe)\n",
    "# - base: usa o BASE_SUBMISSION válido\n",
    "# - raw: usa o BASE_SUBMISSION_RAW (mesmo que tenha overlap; útil se seu CSV é bom mas inválido)\n",
    "HUNT_BASE_MODE = \"raw\" if bool(globals().get(\"BASE_WAS_INVALID\", False)) else \"best\"  # best | base | raw\n",
    "\n",
    "TRY_DIRECT = True  # usa o output direto do hunt (soluções independentes por n)\n",
    "USE_MOTHER_PREFIX = True  # também tenta mother-prefix (nested) a partir do NMAX\n",
    "MOTHER_REORDERS = [\"radial\", \"greedybbox\"]  # radial | greedybbox | none\n",
    "\n",
    "# Para ficar <70 você precisa melhorar o score completo (1..200), não só N=200.\n",
    "TARGET_RANGE = \"1,200\"  # ex: \"200,200\" (só N=200) ou \"1,200\" (pipeline completo)\n",
    "\n",
    "# Seeds em blocos (o notebook continua gerando blocos até atingir TARGET_SCORE)\n",
    "SEED_START = 4000\n",
    "SEED_BLOCK_SIZE = 16\n",
    "MAX_BLOCKS = 1 if MODE == \"quick\" else None  # None = roda até você parar/atingir TARGET_SCORE\n",
    "\n",
    "if MODE == \"quick\":\n",
    "    PASSES = 600\n",
    "    ATTEMPTS_PER_PASS = 200\n",
    "    POST_OPT = False\n",
    "    POST_ITERS = 20_000\n",
    "    POST_RESTARTS = 2\n",
    "    SMOOTH_WINDOWS = [0, 60]\n",
    "    IMPROVE_N200_OPTIONS = [False]\n",
    "elif MODE == \"full\":\n",
    "    PASSES = 5000\n",
    "    ATTEMPTS_PER_PASS = 500\n",
    "    POST_OPT = True\n",
    "    POST_ITERS = 200_000\n",
    "    POST_RESTARTS = 32\n",
    "    SMOOTH_WINDOWS = [0, 60, 120, 180, 199]\n",
    "    IMPROVE_N200_OPTIONS = [False, True]\n",
    "else:  # target70\n",
    "    PASSES = 8000\n",
    "    ATTEMPTS_PER_PASS = 800\n",
    "    POST_OPT = True\n",
    "    POST_ITERS = 600_000\n",
    "    POST_RESTARTS = 64\n",
    "    SMOOTH_WINDOWS = [0, 60, 80, 100, 120, 140, 160, 180, 199]\n",
    "    IMPROVE_N200_OPTIONS = [False, True]\n",
    "\n",
    "# Blend/repair: tenta aproveitar candidatos com overlap sem rodar `autofix_submission` inteiro.\n",
    "# Ideia: primeiro faz blend barato (apenas puzzles já válidos), depois tenta reparar (finalize) só os TOPK candidatos.\n",
    "BLEND_REPAIR_TOPK = 0 if MODE == \"quick\" else 6\n",
    "BLEND_REPAIR_MODE = \"none\" if MODE == \"quick\" else \"finalize\"  # none | finalize\n",
    "BLEND_REPAIR_MAX_PUZZLES = 0 if MODE == \"quick\" else 25\n",
    "BLEND_REPAIR_MIN_GAIN = 0.0000  # ganho mínimo estimado em (s^2/n) para tentar repair\n",
    "BLEND_REPAIR_N_MIN = 1\n",
    "BLEND_REPAIR_N_MAX = None  # ex: 200\n",
    "\n",
    "# Knobs do improve_n200 (só tem efeito se JAX estiver instalado)\n",
    "if MODE == \"quick\":\n",
    "    N200_INSERT_CENTERS = 6000\n",
    "    N200_INSERT_ANGLES = 30\n",
    "    N200_INSERT_PAD_SCALE = 0.20\n",
    "    N200_SA_BATCH = 32\n",
    "    N200_SA_STEPS = 8000\n",
    "else:\n",
    "    N200_INSERT_CENTERS = 20000\n",
    "    N200_INSERT_ANGLES = 60\n",
    "    N200_INSERT_PAD_SCALE = 0.20\n",
    "    N200_SA_BATCH = 64\n",
    "    N200_SA_STEPS = 50000\n",
    "\n",
    "print({\n",
    "    \"MODE\": MODE,\n",
    "    \"HUNT_BASE_MODE\": HUNT_BASE_MODE,\n",
    "    \"TRY_DIRECT\": TRY_DIRECT,\n",
    "    \"SEED_START\": SEED_START,\n",
    "    \"SEED_BLOCK_SIZE\": SEED_BLOCK_SIZE,\n",
    "    \"MAX_BLOCKS\": MAX_BLOCKS,\n",
    "    \"TARGET_RANGE\": TARGET_RANGE,\n",
    "    \"PASSES\": PASSES,\n",
    "    \"ATTEMPTS_PER_PASS\": ATTEMPTS_PER_PASS,\n",
    "    \"POST_OPT\": POST_OPT,\n",
    "    \"POST_ITERS\": POST_ITERS,\n",
    "    \"POST_RESTARTS\": POST_RESTARTS,\n",
    "    \"SMOOTH_WINDOWS\": SMOOTH_WINDOWS,\n",
    "    \"IMPROVE_N200_OPTIONS\": IMPROVE_N200_OPTIONS,\n",
    "    \"USE_MOTHER_PREFIX\": USE_MOTHER_PREFIX,\n",
    "    \"MOTHER_REORDERS\": MOTHER_REORDERS,\n",
    "    \"BLEND_REPAIR_TOPK\": BLEND_REPAIR_TOPK,\n",
    "    \"BLEND_REPAIR_MODE\": BLEND_REPAIR_MODE,\n",
    "    \"BLEND_REPAIR_MAX_PUZZLES\": BLEND_REPAIR_MAX_PUZZLES,\n",
    "    \"BLEND_REPAIR_MIN_GAIN\": BLEND_REPAIR_MIN_GAIN,\n",
    "    \"BLEND_REPAIR_N_MIN\": BLEND_REPAIR_N_MIN,\n",
    "    \"BLEND_REPAIR_N_MAX\": BLEND_REPAIR_N_MAX,\n",
    "    \"N200_INSERT_CENTERS\": N200_INSERT_CENTERS,\n",
    "    \"N200_INSERT_ANGLES\": N200_INSERT_ANGLES,\n",
    "    \"N200_INSERT_PAD_SCALE\": N200_INSERT_PAD_SCALE,\n",
    "    \"N200_SA_BATCH\": N200_SA_BATCH,\n",
    "    \"N200_SA_STEPS\": N200_SA_STEPS,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3bf96",
   "metadata": {},
   "source": [
    "## 2. Rodar Hunt + Pós-processamento + Seleção\n",
    "Este loop:\n",
    "- roda `hunt_compact_contact` no intervalo `TARGET_RANGE` (por default `1,200` para melhorar o score completo)\n",
    "- gera o submission por prefixo a partir da solução de N=200\n",
    "- aplica `improve_submission` (smoothing + improve-n200)\n",
    "- valida/score em modo Kaggle\n",
    "- mantém o melhor candidato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd91b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compact_contact: seeds=16 jobs=14 nmax=200 target=200..200\n",
      "[seed=4002] score=72.807999675374 time=102.2s\n",
      "[seed=4005] score=72.807999675374 time=107.1s\n",
      "[seed=4008] score=72.807999675374 time=108.1s\n",
      "[seed=4001] score=72.807999675374 time=108.6s\n",
      "[seed=4012] score=72.807999675374 time=109.4s\n",
      "[seed=4009] score=72.807999675374 time=109.5s\n",
      "[seed=4011] score=72.807999675374 time=110.4s\n",
      "[seed=4006] score=72.807999675374 time=111.3s\n",
      "[seed=4010] score=72.807999675374 time=112.0s\n",
      "[seed=4013] score=72.807999675374 time=113.0s\n",
      "[seed=4003] score=72.807999675374 time=114.8s\n",
      "[seed=4004] score=72.807999675374 time=114.9s\n",
      "[seed=4000] score=72.807999675374 time=115.4s\n",
      "[seed=4007] score=72.807999675374 time=119.6s\n",
      "[seed=4014] score=72.807999675374 time=62.4s\n",
      "[seed=4015] score=72.807999675374 time=60.8s\n",
      "Best single: seed=4002 score=72.807999675374 csv=runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/cc_seed4002.csv\n",
      "Ensemble score (no overlap check): 72.807999675374\n",
      "Running post_opt: /home/marcux777/Santa-2025-Christmas-Tree-Packing-Challenge/bin/post_opt --input runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/ensemble.csv --output runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/ensemble_postopt_raw.csv --iters 200000 --restarts 64 --seed 1 --threads 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-opt complete\n",
      "Initial score: 72.807999675\n",
      "Final score:   72.801975641\n",
      "Phase1 improved: 87\n",
      "Backprop improved: 0\n",
      "Elapsed: 1130.838000000s\n",
      "Saved: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/ensemble_postopt_raw.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[warn] Post-opt blend failed; keeping previous (runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/ensemble.csv): Base CSV has overlap in puzzle 4 (mode=strict).\n",
      "[warn] Post-opt output still overlaps (strict): Overlap detected in puzzle 4\n",
      "Post-opt score (strict, no-overlap): 72.807999675374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth0_no_n200.csv\n",
      "score(no-overlap): 256.303049961088\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 256.303049961088  (4000..4015|smooth=0|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth0_no_n200.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2026-01-11 11:01:17,200:jax._src.xla_bridge:852: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth0_n200.csv\n",
      "score(no-overlap): 256.304870955503\n",
      "s_max: 8.302905\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth60_no_n200.csv\n",
      "score(no-overlap): 104.847051115612\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 104.847051115612  (4000..4015|smooth=60|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth60_no_n200.csv\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth60_n200.csv\n",
      "score(no-overlap): 104.848487138023\n",
      "s_max: 8.298267\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth80_no_n200.csv\n",
      "score(no-overlap): 92.332812118904\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 92.332812118904  (4000..4015|smooth=80|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth80_no_n200.csv\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth80_n200.csv\n",
      "score(no-overlap): 92.334248141314\n",
      "s_max: 8.298267\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth100_no_n200.csv\n",
      "score(no-overlap): 87.563698203225\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 87.563698203225  (4000..4015|smooth=100|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth100_no_n200.csv\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth100_n200.csv\n",
      "score(no-overlap): 87.565134225636\n",
      "s_max: 8.298267\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth120_no_n200.csv\n",
      "score(no-overlap): 84.689174092062\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 84.689174092062  (4000..4015|smooth=120|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth120_no_n200.csv\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth120_n200.csv\n",
      "score(no-overlap): 84.690610114473\n",
      "s_max: 8.298267\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth140_no_n200.csv\n",
      "score(no-overlap): 82.326099322135\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 82.326099322135  (4000..4015|smooth=140|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth140_no_n200.csv\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth140_n200.csv\n",
      "score(no-overlap): 82.327535344546\n",
      "s_max: 8.298267\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth160_no_n200.csv\n",
      "score(no-overlap): 81.283365942750\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 81.283365942750  (4000..4015|smooth=160|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth160_no_n200.csv\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth160_n200.csv\n",
      "score(no-overlap): 81.284801965160\n",
      "s_max: 8.298267\n",
      "wrote: runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth180_no_n200.csv\n",
      "score(no-overlap): 81.121573390584\n",
      "s_max: 8.280944\n",
      "\n",
      "[new best] 81.121573390584  (4000..4015|smooth=180|no_n200) -> runs/notebook_optimization_hunt_20260111_103707/hunt_seeds_4000-4015/submission_improved_smooth180_no_n200.csv\n"
     ]
    }
   ],
   "source": [
    "if CURRENT_BEST is None:\n",
    "    raise RuntimeError(\"CURRENT_BEST is None (run the setup cells first)\")\n",
    "\n",
    "from santa_packing.blend import blend_submissions\n",
    "\n",
    "best: Candidate = Candidate(label=\"BASE\", csv_path=BASE_SUBMISSION, score=float(CURRENT_BEST))\n",
    "all_rows: list[Candidate] = [best]\n",
    "seed_blocks_run: list[str] = []\n",
    "stop = False\n",
    "\n",
    "seed = int(SEED_START)\n",
    "blocks_run = 0\n",
    "while True:\n",
    "    if MAX_BLOCKS is not None and blocks_run >= int(MAX_BLOCKS):\n",
    "        print(f\"[stop] reached MAX_BLOCKS={MAX_BLOCKS}\")\n",
    "        break\n",
    "\n",
    "    block = f\"{seed}..{seed + int(SEED_BLOCK_SIZE) - 1}\"\n",
    "    seed_blocks_run.append(block)\n",
    "    seed += int(SEED_BLOCK_SIZE)\n",
    "    blocks_run += 1\n",
    "\n",
    "    block_dir = RUN_DIR / f\"hunt_seeds_{block.replace('..','-').replace(',','_')}\"\n",
    "\n",
    "    hmode = str(HUNT_BASE_MODE).lower().strip()\n",
    "    if hmode == \"best\":\n",
    "        hunt_base = best.csv_path\n",
    "    elif hmode == \"raw\":\n",
    "        hunt_base = BASE_SUBMISSION_RAW\n",
    "    else:  # base\n",
    "        hunt_base = BASE_SUBMISSION\n",
    "\n",
    "    hunt_out = run_hunt_compact_contact(\n",
    "        base=hunt_base,\n",
    "        out_dir=block_dir,\n",
    "        seeds=block,\n",
    "        target_range=TARGET_RANGE,\n",
    "        passes=PASSES,\n",
    "        attempts_per_pass=ATTEMPTS_PER_PASS,\n",
    "        post_opt=POST_OPT,\n",
    "        post_iters=POST_ITERS,\n",
    "        post_restarts=POST_RESTARTS,\n",
    "    )\n",
    "\n",
    "    base_candidates: list[tuple[str, Path]] = []\n",
    "    if bool(TRY_DIRECT):\n",
    "        base_candidates.append((\"direct\", hunt_out))\n",
    "\n",
    "    if bool(USE_MOTHER_PREFIX):\n",
    "        for reorder in list(MOTHER_REORDERS):\n",
    "            mother_tag = f\"mother_{str(reorder).lower()}\"\n",
    "            mother_out = block_dir / f\"submission_mother_prefix_{str(reorder).lower()}.csv\"\n",
    "            mother_out = generate_mother_prefix(hunt_out, mother_out, reorder=str(reorder))\n",
    "            base_candidates.append((mother_tag, mother_out))\n",
    "\n",
    "    if not base_candidates:\n",
    "        raise RuntimeError(\"No base strategy enabled (set TRY_DIRECT and/or USE_MOTHER_PREFIX).\")\n",
    "\n",
    "    # 1) Gerar candidatos (smoothing + n200) e tentar blend barato (apenas puzzles já válidos)\n",
    "    ranked: list[tuple[float, str, Path]] = []  # (score_no_check, label, path)\n",
    "    for base_label, base_for_post in base_candidates:\n",
    "        for w in SMOOTH_WINDOWS:\n",
    "            for improve_n200 in IMPROVE_N200_OPTIONS:\n",
    "                tag = \"n200\" if bool(improve_n200) else \"no_n200\"\n",
    "                label = f\"{block}|{base_label}|smooth={w}|{tag}\"\n",
    "                improved = block_dir / f\"submission_improved_{base_label}_smooth{int(w)}_{tag}.csv\"\n",
    "                improved = improve_submission(base_for_post, improved, smooth_window=int(w), improve_n200=bool(improve_n200))\n",
    "\n",
    "                no_check = score_csv(improved, overlap_mode=str(OVERLAP_MODE), check_overlap=False)\n",
    "                ranked.append((float(no_check), label, improved))\n",
    "\n",
    "                blended = block_dir / f\"submission_blend_{base_label}_smooth{int(w)}_{tag}.csv\"\n",
    "                blended, meta = blend_submissions(\n",
    "                    base_csv=best.csv_path,\n",
    "                    candidate_csv=improved,\n",
    "                    out_csv=blended,\n",
    "                    nmax=int(NMAX),\n",
    "                    overlap_mode=str(OVERLAP_MODE),\n",
    "                    repair_mode=\"none\",\n",
    "                )\n",
    "\n",
    "                if int(meta.get(\"used_candidate\", 0)) <= 0:\n",
    "                    continue\n",
    "\n",
    "                ok, s, err = try_score(blended)\n",
    "                if not ok:\n",
    "                    print(f\"[skip] blend inválido: {err}\")\n",
    "                    continue\n",
    "\n",
    "                row = Candidate(label=label, csv_path=blended, score=float(s))\n",
    "                all_rows.append(row)\n",
    "\n",
    "                if row.score < best.score:\n",
    "                    best = row\n",
    "                    print(f\"\\n[new best] {best.score:.12f}  ({best.label}) -> {best.csv_path}\")\n",
    "                    if TARGET_SCORE is not None and best.score <= float(TARGET_SCORE):\n",
    "                        print(f\"[done] reached TARGET_SCORE={TARGET_SCORE}\")\n",
    "                        stop = True\n",
    "                        break\n",
    "\n",
    "            if stop:\n",
    "                break\n",
    "        if stop:\n",
    "            break\n",
    "\n",
    "    if stop:\n",
    "        break\n",
    "\n",
    "    # 2) Repair (bounded): tenta reparar apenas TOPK candidatos mais promissores\n",
    "    if int(BLEND_REPAIR_TOPK) > 0 and str(BLEND_REPAIR_MODE).lower().strip() != \"none\":\n",
    "        ranked.sort(key=lambda t: t[0])\n",
    "        for rank, (_no_check, label, cand_path) in enumerate(ranked[: int(BLEND_REPAIR_TOPK)], start=1):\n",
    "            slug = label.replace(\"..\", \"-\").replace(\"|\", \"_\")\n",
    "            out_path = block_dir / f\"submission_blend_repair{rank}_{slug}.csv\"\n",
    "            out_path, meta = blend_submissions(\n",
    "                base_csv=best.csv_path,\n",
    "                candidate_csv=cand_path,\n",
    "                out_csv=out_path,\n",
    "                nmax=int(NMAX),\n",
    "                overlap_mode=str(OVERLAP_MODE),\n",
    "                repair_mode=str(BLEND_REPAIR_MODE).lower().strip(),\n",
    "                repair_seed=123,\n",
    "                repair_max_puzzles=int(BLEND_REPAIR_MAX_PUZZLES),\n",
    "                repair_min_gain=float(BLEND_REPAIR_MIN_GAIN),\n",
    "                repair_n_min=int(BLEND_REPAIR_N_MIN),\n",
    "                repair_n_max=None if BLEND_REPAIR_N_MAX is None else int(BLEND_REPAIR_N_MAX),\n",
    "            )\n",
    "\n",
    "            if int(meta.get(\"used_candidate\", 0)) <= 0:\n",
    "                continue\n",
    "\n",
    "            ok, s, err = try_score(out_path)\n",
    "            if not ok:\n",
    "                print(f\"[skip] repair inválido: {err}\")\n",
    "                continue\n",
    "\n",
    "            row = Candidate(label=f\"{label}|repair_top{rank}\", csv_path=out_path, score=float(s))\n",
    "            all_rows.append(row)\n",
    "\n",
    "            if row.score < best.score:\n",
    "                best = row\n",
    "                print(f\"\\n[new best] {best.score:.12f}  ({best.label}) -> {best.csv_path}\")\n",
    "                if TARGET_SCORE is not None and best.score <= float(TARGET_SCORE):\n",
    "                    print(f\"[done] reached TARGET_SCORE={TARGET_SCORE}\")\n",
    "                    stop = True\n",
    "                    break\n",
    "\n",
    "    if stop:\n",
    "        break\n",
    "\n",
    "save_leaderboard(all_rows, RUN_DIR / \"leaderboard.json\")\n",
    "print(f\"\\nTried {len(all_rows)} candidates\")\n",
    "print(f\"Best: {best}\")\n",
    "print(f\"Target to beat: {CURRENT_BEST}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda5dd4",
   "metadata": {},
   "source": [
    "## 3. Finalizar\n",
    "Exporta o melhor CSV para `submission.csv` (raiz) e cria um bundle em `submissions/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcbe888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from santa_packing.workflow import archive_submission\n",
    "\n",
    "if best is None:\n",
    "    raise RuntimeError(\"No valid candidates produced\")\n",
    "\n",
    "res = archive_submission(\n",
    "    best.csv_path,\n",
    "    nmax=int(NMAX),\n",
    "    overlap_mode=str(OVERLAP_MODE),\n",
    "    name=f\"notebook_hunt_{RUN_TAG}\",\n",
    "    export=True,\n",
    "    export_path=project_root / \"submission.csv\",\n",
    "    extra_meta={\n",
    "        \"notebook\": \"notebooks/02_optimization_hunt.ipynb\",\n",
    "        \"run_dir\": str(RUN_DIR),\n",
    "        \"mode\": MODE,\n",
    "        \"base_submission_raw\": str(BASE_SUBMISSION_RAW),\n",
    "        \"base_submission_valid\": str(BASE_SUBMISSION),\n",
    "        \"base_was_invalid\": bool(BASE_WAS_INVALID),\n",
    "        \"base_invalid_action\": str(BASE_INVALID_ACTION),\n",
    "        \"seed_blocks\": list(seed_blocks_run),\n",
    "        \"seed_start\": int(SEED_START),\n",
    "        \"seed_block_size\": int(SEED_BLOCK_SIZE),\n",
    "        \"max_blocks\": MAX_BLOCKS,\n",
    "        \"hunt_base_mode\": str(HUNT_BASE_MODE),\n",
    "        \"target_range\": str(TARGET_RANGE),\n",
    "        \"smooth_windows\": list(SMOOTH_WINDOWS),\n",
    "        \"improve_n200_options\": list(IMPROVE_N200_OPTIONS),\n",
    "        \"try_direct\": bool(TRY_DIRECT),\n",
    "        \"use_mother_prefix\": bool(USE_MOTHER_PREFIX),\n",
    "        \"mother_reorders\": list(MOTHER_REORDERS),\n",
    "        \"blend_repair_topk\": int(BLEND_REPAIR_TOPK),\n",
    "        \"blend_repair_mode\": str(BLEND_REPAIR_MODE),\n",
    "        \"blend_repair_max_puzzles\": int(BLEND_REPAIR_MAX_PUZZLES),\n",
    "        \"blend_repair_min_gain\": float(BLEND_REPAIR_MIN_GAIN),\n",
    "        \"blend_repair_n_min\": int(BLEND_REPAIR_N_MIN),\n",
    "        \"blend_repair_n_max\": None if BLEND_REPAIR_N_MAX is None else int(BLEND_REPAIR_N_MAX),\n",
    "        \"best_label\": best.label,\n",
    "        \"best_path\": str(best.csv_path),\n",
    "        \"best_score_observed\": float(best.score),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Archived: {res.run_dir}\")\n",
    "print(f\"Exported: {res.exported_submission}\")\n",
    "print(f\"Score: {res.score:.12f} (overlap_mode={OVERLAP_MODE})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
